{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a1f77a",
   "metadata": {},
   "source": [
    "# Model building\n",
    "\n",
    "In this notebook we build LSTM models using a processed text data from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4203b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/chaitanya/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "%matplotlib inline\n",
    "fig_params = {\n",
    "    'legend.fontsize': 18,\n",
    "    'axes.labelsize': 18,\n",
    "    'axes.titlesize': 20,\n",
    "    'xtick.labelsize': 16,\n",
    "    'ytick.labelsize': 16,\n",
    "    'axes.facecolor': '#D9DDD1'\n",
    "}\n",
    "plt.rcParams.update(fig_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b62b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('./data/train_processed.pkl')\n",
    "df_val = pd.read_pickle('./data/val_processed.pkl')\n",
    "df_test = pd.read_pickle('./data/test_processed.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e677bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=12000, oov_token='<UKN>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2993f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df_train['processed'])\n",
    "pickle.dump(tokenizer, open('./tokenizer_model.model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5910f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer()\n",
    "# cv.fit(df_train['processed'])\n",
    "\n",
    "# cv.transform(df_train['processed']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a50d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(tokenizer, df, maxlen):\n",
    "    sequence = tokenizer.texts_to_sequences(df)\n",
    "    padded = pad_sequences(sequences=sequence,\n",
    "                           maxlen=maxlen,\n",
    "                           padding='post',\n",
    "                           truncating='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03219600",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 550\n",
    "X_tr = np.array(get_sequence(tokenizer, df_train['processed'], maxlen))\n",
    "X_cv = np.array(get_sequence(tokenizer, df_val['processed'], maxlen))\n",
    "X_test = np.array(get_sequence(tokenizer, df_test['processed'], maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a88e0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df_train['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15a9b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = le.transform(df_train['stars'])\n",
    "y_cv = le.transform(df_val['stars'])\n",
    "y_test = le.transform(df_test['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54c204b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147140, 550) (147140,)\n",
      "(36785, 550) (36785,)\n",
      "(45982, 550) (45982,)\n"
     ]
    }
   ],
   "source": [
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_cv.shape, y_cv.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fcc78e",
   "metadata": {},
   "source": [
    "## Create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e29d5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36f98df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6336db3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 550, 16)           192000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               46800     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 239,305\n",
      "Trainable params: 239,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Embedding(input_dim=12000, output_dim=16, input_length=maxlen))\n",
    "model1.add(LSTM(100))\n",
    "model1.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model1.compile(loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fefd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 147140 samples, validate on 36785 samples\n",
      "Epoch 1/15\n",
      "147140/147140 [==============================] - 2173s 15ms/sample - loss: 1.4391 - acc: 0.3435 - val_loss: 1.4407 - val_acc: 0.3463\n",
      "Epoch 2/15\n",
      "147140/147140 [==============================] - 2426s 16ms/sample - loss: 1.4374 - acc: 0.3440 - val_loss: 1.4392 - val_acc: 0.3463\n",
      "Epoch 3/15\n",
      "147140/147140 [==============================] - 2672s 18ms/sample - loss: 1.4371 - acc: 0.3457 - val_loss: 1.4386 - val_acc: 0.3463\n",
      "Epoch 4/15\n",
      "147140/147140 [==============================] - 2003s 14ms/sample - loss: 1.4369 - acc: 0.3453 - val_loss: 1.4382 - val_acc: 0.3463\n",
      "Epoch 5/15\n",
      "137600/147140 [===========================>..] - ETA: 2:05 - loss: 1.4375 - acc: 0.3454"
     ]
    }
   ],
   "source": [
    "model1.fit(X_tr, y_tr, validation_data=(X_cv, y_cv), epochs=15, batch_size=64,verbose=1,\n",
    "          callbacks=[early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(model1.history.history)\n",
    "history[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model1.predict_classes(X_tr)\n",
    "y_cv_pred = model1.predict_classes(X_cv)\n",
    "\n",
    "print('=' * 20)\n",
    "print('training data \\n', classification_report(y_tr, y_tr_pred))\n",
    "print('=' * 20)\n",
    "print('validation data \\n', classification_report(y_cv, y_cv_pred))\n",
    "print('=' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100f0042",
   "metadata": {},
   "source": [
    "## RNN with dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=12000, output_dim=16, input_length=maxlen))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(LSTM(100))\n",
    "model2.add(Dropout(0.4))\n",
    "model2.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c35c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_tr, y_tr, validation_data=(X_cv, y_cv), epochs=25, batch_size=64, verbose=1,\n",
    "          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(model2.history.history)\n",
    "history[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bbc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model2.predict_classes(X_tr)\n",
    "y_cv_pred = model2.predict_classes(X_cv)\n",
    "\n",
    "print('=' * 20)\n",
    "print('training data \\n', classification_report(y_tr, y_tr_pred))\n",
    "print('=' * 20)\n",
    "print('validation data \\n', classification_report(y_cv, y_cv_pred))\n",
    "print('=' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0fd57c",
   "metadata": {},
   "source": [
    "## RNN with bidirectional LSTM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbd3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Embedding(input_dim=12000, output_dim=16, input_length=maxlen))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Bidirectional(LSTM(100)))\n",
    "model3.add(Dropout(0.4))\n",
    "model3.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "               optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2dad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X_tr,\n",
    "           y_tr,\n",
    "           validation_data=(X_cv, y_cv),\n",
    "           epochs=25,\n",
    "           batch_size=64,\n",
    "           verbose=1,\n",
    "           callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e865e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(model3.history.history)\n",
    "history[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = model3.predict_classes(X_tr)\n",
    "y_cv_pred = model3.predict_classes(X_cv)\n",
    "\n",
    "print('=' * 20)\n",
    "print('training data \\n', classification_report(y_tr, y_tr_pred))\n",
    "print('=' * 20)\n",
    "print('validation data \\n', classification_report(y_cv, y_cv_pred))\n",
    "print('=' * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5782adb",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred1 = model1.predict_classes(X_test)\n",
    "y_test_pred2 = model2.predict_classes(X_test)\n",
    "y_test_pred3 = model3.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4cbcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 20)\n",
    "print(classification_report(y_test, y_test_pred1))\n",
    "print('=' * 20)\n",
    "print(classification_report(y_test, y_test_pred2))\n",
    "print('=' * 20)\n",
    "print(classification_report(y_test, y_test_pred3))\n",
    "print('=' * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
